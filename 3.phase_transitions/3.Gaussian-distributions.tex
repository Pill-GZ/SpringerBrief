
We recall three facts of Gaussian distributions that will be used in the proofs later.

We first state the relative stability of iid standard Gaussian random variables,
Since the standard Gaussian distribution falls in the class of asymptotically generalized Gaussians (AGG; see Definition \ref{def:AGG}), by Example \ref{exmp:AGG}, we know that the triangular array ${\cal E} = \{\left(\epsilon_p(i)\right)_{i=1}^p, p\in\N\}$ has relatively stable (RS) maxima in the sense of \eqref{eq:RS-condition}, i.e.,
\begin{equation} \label{eq:relative-stability-Gaussian-maxima}
    \frac{1}{u_{p}} \max_{i=1,\ldots,p} \epsilon_p(i) \xrightarrow{\P} 1,\quad \text{as }\;p\to\infty,
\end{equation}
where $u_p$ is the $(1/p)$-th upper quantile as defined in \eqref{eq:AGG-quantiles}.
Similarly, since the array ${\cal E}$ has distributions symmetric around 0, it also has relatively stable minima
\begin{equation} \label{eq:relative-stability-Gaussian-minima}
    \frac{1}{u_{p}} \min_{i=1,\ldots,p} \epsilon_p(i) \xrightarrow{\P} -1,\quad \text{as }\;p\to\infty.
\end{equation}

The second fact is on the well-known bounds for the Mill's ratio of Gaussian tails.
Let $\Phi$ denote the CDF of the standard Gaussian distribution and $\phi$ its density.
One can show that for all $x>0$ we have
\begin{equation} \label{eq:Mills-ratio}
    \frac{x}{1+x^2}\phi(x) \le \overline{\Phi}(x) = 1-\Phi(x) \le \frac{1}{x}\phi(x),
\end{equation}
using e.g., integration by parts.

The third fact is the stochastic monotonicity of the Gaussian location family. 
In fact, for all location families $\{F_\delta(x)\}_\delta$ where $F_\delta(x) = F(x-\delta)$, we have,
\begin{equation} \label{eq:stochastic-monotonicity-Gaussian}
    F_{\delta_1}(t) \ge F_{\delta_2}(t), \quad \text{for all}\quad t\in\mathbb{R}\quad\text{and all}\quad \delta_1 \le \delta_2.
\end{equation}
Relation \eqref{eq:stochastic-monotonicity-Gaussian} holds, of course, when $F$ is the standard Gaussian distribution. 
