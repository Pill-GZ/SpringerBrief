The strong classification boundaries extend beyond the AGG models.
As our analysis in Section \ref{sec:boundary} suggests, all additive error models where the errors have URS maxima demonstrate this phase transition phenomenon under appropriate parametrization of the sparsity and signal sizes.
We derive explicit boundaries for two additional classes of models under the general form of the additive noise models \eqref{eq:model-additive}, with heavier and lighter tails than the AGG models, respectively. 

We would like to point out that the sparsity and signal sizes can be re-parametrized for the boundaries to have different shapes.
For example in the case of Gaussian errors, if we re-parametrize sparsity $s$ with 
$\widetilde{\beta} = 2 - \left(1 + \sqrt{1-\beta}\right)^2$ where $\widetilde{\beta}\in(0,1)$, then the signal sparsity would have a slightly more complicated form:
$$
\left|S_p\right| = \left\lfloor p^{1-\beta} \right\rfloor = \left\lfloor p^{\left(\sqrt{2 - \widetilde{\beta}} - 1\right)^2}\right\rfloor,
$$
while the strong classification boundary would take on the simpler form:
\begin{equation}\label{eq:altenative-parametrization}
g(\beta) = \widetilde{g}(\widetilde{\beta}) = 2 - \widetilde{\beta}.
\end{equation}
In the next two classes of models we will adopt parametrizations such that the boundaries are of the form $\widetilde{g}$ in \eqref{eq:altenative-parametrization}.

\subsection{Additive error models with heavier-than-AGG tails}

Distributions such as the log-normal have heavier tails than the AGG model, yet the tails are nevertheless rapidly-varying. 
Therefore, Proposition \ref{prop:rapid-varying-tails} applies, and we expect to see phase-transition-type results when the additive errors have these heavier-than-AGG tails.

\begin{example}[Heavier than AGG] \label{exmp:heavier-than-AGG}
Let $\gamma>1$, $c>0$, and suppose that
\begin{equation} \label{eq:heavier-than-AGG}
    \log{\overline{F}(x)} = - \left(\log x\right)^\gamma \left(c+M(x)\right),
\end{equation}
where $\lim_{x\to\infty} M(x)\log^\gamma{x}= 0$. Then, Relation \eqref{eq:rapid-varying-tails} holds under 
model \eqref{eq:heavier-than-AGG}. Further, if the entries in the array are independent, the 
maxima are relatively stable.

The behavior of the quantiles $u_p$ in this model is as follows. As $p\to\infty,$
\begin{equation*}
    u_p \sim \exp{\left\{\left(c^{-1}\log{p}\right)^{1/\gamma}\right\}}
    \iff c\left(\log{u_p}\right)^{\gamma} + o(1) = \log(p) = - \log \overline{F}(u_p).
\end{equation*}
since $u_p$ diverges, and $M(u_p)$ is $o((\log^\gamma u_p)^{-1})$.
\end{example}


Following Example \ref{exmp:heavier-than-AGG}, assume that the errors in Model \eqref{eq:model-additive} have rapidly varying right tails
\begin{equation} \label{eq:heavier-than-AGG-boundary-1}
    \log{\overline{F}(x)} = - \left(\log x\right)^\gamma \left(c+M(x)\right),
\end{equation}
as $x\to \infty$, and left tails
\begin{equation} \label{eq:heavier-than-AGG-boundary-2}
    \log{{F}(x)} = - \left(\log{(-x)}\right)^\gamma \left(c+M(-x)\right),
\end{equation}
as $x\to -\infty$.

\begin{theorem} \label{thm:heavier-than-AGG}
Suppose the marginals $F$ follows \eqref{eq:heavier-than-AGG-boundary-1} and \eqref{eq:heavier-than-AGG-boundary-2}.
Let
$$
k(\beta) = \log{p} - \left((\log{p})^{1/\gamma} + \log{(1-\beta)}\right)^\gamma,
$$
and let the signal $\mu$ have 
$$|S_p| = \left\lfloor pe^{-k(\beta)} \right\rfloor$$
non-zero entries. Assume the magnitudes of non-zero signal entries are in the range between
$$\underline{\Delta} = \exp{\left\{(\log{p})^{1/\gamma}\right\}}\underline{r}
\quad\text{and}\quad
\overline{\Delta} = \exp{\left\{(\log{p})^{1/\gamma}\right\}}\overline{r}.$$
If $\underline{r} > \widetilde{g}(\beta) = 2 - \beta$, then Bonferroni's procedure $\widehat{S}_p$ (defined in \eqref{eq:Bonferroni-procedure}) with appropriately calibrated FWER $\alpha\to 0$ achieves asymptotic perfect support recovery, under arbitrary dependence of the errors.

On the other hand, when the errors are uniformly relatively stable, if $\overline{r} < \widetilde{g}(\beta) = 2 - \beta$, then no thresholding procedure can achieve asymptotic perfect support recovery with positive probability.
\end{theorem}


\subsection{Additive error models with lighter-than-AGG tails}


Similar to how Proposition \ref{prop:rapid-varying-tails} applies to models with heavier-than-AGG tails, it also to error models with lighter tails than the AGG class.

\begin{example}[Lighter than AGG] \label{exmp:lighter-than-AGG}
With $\nu>0$, and $L(x)$ a slowly varying function, the class of distributions
\begin{equation} \label{eq:lighter-than-AGG}
    \log{\overline{F}(x)} = - \exp{\left\{x^\nu L(x)\right\}},
\end{equation}
is rapidly varying.
The quantiles can be derived explicitly in a subclass of \eqref{eq:lighter-than-AGG} where $L(x)\to 1$, or equivalently, when $\log{|\log{\overline{F}(x)}|}\sim x^\nu$,
\begin{equation*}
    u_p \sim \left(\log \log{p}\right)^{1/\nu}
    \iff \exp{\left\{u_p^\nu\left(1+o(1)\right)\right\}} = \log(p) = - \log \overline{F}(u_p).
\end{equation*}
\end{example}
%The proofs of the rapid variation of the distributions in Examples \ref{exmp:heavier-than-AGG} and \ref{exmp:lighter-than-AGG} are entirely analogous to that of Example \ref{exmp:AGG}, and omitted.


Following Example \ref{exmp:lighter-than-AGG}, assume that errors in Model \eqref{eq:model-additive} has rapidly varying right tails
\begin{equation} \label{eq:lighter-than-AGG-boundary-1}
        \log{\overline{F}(x)} = - \exp{\left\{x^\nu L(x)\right\}},
\end{equation}
where $L(x)$ is a slowly varying function, as $x\to\infty$, and left tails
\begin{equation} \label{eq:lighter-than-AGG-boundary-2}
        \log{\overline{F}(x)} = - \exp{\left\{-x^\nu L(-x)\right\}},
\end{equation}
as $x\to -\infty$.

The phase transition results in multiple testing problems under such tail assumptions is characterizes as follows.

\begin{theorem} \label{thm:lighter-than-AGG}
Suppose marginals $F$ follow \eqref{eq:lighter-than-AGG-boundary-1} and \eqref{eq:lighter-than-AGG-boundary-2}.
Let
$$
k(\beta) = \log{p} - \left(\log(p)\right)^{(1-\beta)^\nu},
$$
and let the signal $\mu$ have 
$$|S_p| = \left\lfloor pe^{-k(\beta)} \right\rfloor$$
non-zero entries. Assume the magnitudes of non-zero signal entries are in the range between
$$\underline{\Delta} = \log{\log{p}}^{1/\nu}\underline{r}
\quad\text{and}\quad
\overline{\Delta} = \log{\log{p}}^{1/\nu}\overline{r}.$$
If $\underline{r} > \widetilde{g}(\beta) = 2 - \beta$, then Bonferroni's procedure $\widehat{S}_p$ (defined in \eqref{eq:Bonferroni-procedure}) with appropriately calibrated FWER $\alpha\to 0$ achieves asymptotic perfect support recovery, under arbitrary dependence of the errors.

On the other hand, when the errors are uniformly relatively stable, if $\overline{r} < \widetilde{g}(\beta) = 2 - \beta$, then no thresholding procedure can achieve asymptotic perfect support recovery with positive probability.
\end{theorem}


